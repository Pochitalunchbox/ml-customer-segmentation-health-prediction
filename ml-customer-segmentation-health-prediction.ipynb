{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f07bd-5961-4670-a733-c0d2902bc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "https://www.kaggle.com/datasets/shwetabh123/mall-customers\n",
    "https://www.kaggle.com/datasets/camnugent/california-housing-prices\n",
    "https://www.kaggle.com/datasets/abhi8923shriv/liver-disease-patient-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d4718-db7e-4faa-b9c7-01aa911b7f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Mall_customers.csv')\n",
    "\n",
    "# 1. Correlation Matrix\n",
    "# Select numerical columns for correlation (Age, Annual Income, and Spending Score)\n",
    "df_numeric = df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d9692-8497-4034-a8b6-cc77ebebde29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Plot \n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Distribution for Age\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(df['Age'], kde=True, color='skyblue')\n",
    "plt.title('Distribution of Age')\n",
    "\n",
    "# Distribution for Annual Income \n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(df['Annual Income (k$)'], kde=True, color='green')\n",
    "plt.title('Distribution of Annual Income (k$)')\n",
    "\n",
    "# Distribution for Spending Score \n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(df['Spending Score (1-100)'], kde=True, color='orange')\n",
    "plt.title('Distribution of Spending Score (1-100)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24758c-9879-4c94-bbe8-daa94927afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Mall_customers.csv')\n",
    "\n",
    "# Select features for clustering\n",
    "X = df[['Age', 'Spending Score (1-100)', 'Annual Income (k$)']]\n",
    "\n",
    "# Standardize the data \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Elbow Method for Optimal K\n",
    "inertia = []  # Store inertia values for each K\n",
    "for k in range(1, 11):  # Test different values of K (1 to 10 clusters)\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow (Scree) Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 11), inertia, marker='o', color='b', linestyle='--')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (Sum of Squared Distances)')\n",
    "plt.xticks(range(1, 11))\n",
    "plt.grid(True)\n",
    "\n",
    "# Find the optimal number of clusters (K) based on the \"elbow\"\n",
    "optimal_k = 3  # Based on the elbow method or visual inspection (assumed K=3 for this case)\n",
    "\n",
    "plt.axvline(x=optimal_k, color='red', linestyle=':', label=f'Optimal K={optimal_k}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Apply K-Means with the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Step 1: Box Plot for Age vs Cluster\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([df[df['Cluster'] == i]['Age'] for i in range(optimal_k)], labels=[f'Cluster {i}' for i in range(optimal_k)])\n",
    "plt.title('Box Plot of Age by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Box Plot for Spending Score vs Cluster\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([df[df['Cluster'] == i]['Spending Score (1-100)'] for i in range(optimal_k)], labels=[f'Cluster {i}' for i in range(optimal_k)])\n",
    "plt.title('Box Plot of Spending Score by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Spending Score (1-100)')\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Box Plot for Income vs Cluster\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([df[df['Cluster'] == i]['Annual Income (k$)'] for i in range(optimal_k)], labels=[f'Cluster {i}' for i in range(optimal_k)])\n",
    "plt.title('Box Plot of Income by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Annual Income (k$)')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Calculate and Display Mean Values for Each Cluster\n",
    "cluster_means = df.groupby('Cluster')[['Age', 'Spending Score (1-100)', 'Annual Income (k$)']].mean()\n",
    "print(\"\\nMean Values for Each Cluster:\")\n",
    "print(cluster_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff0788-fb3e-41aa-bc0f-1b4cf508dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Mall_customers.csv')\n",
    "\n",
    "# Select features for clustering (Age, Spending Score, and Annual Income)\n",
    "X = df[['Age', 'Spending Score (1-100)', 'Annual Income (k$)']]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply GMM with 3 clusters\n",
    "optimal_k = 3  # Number of clusters (set manually or from previous analysis)\n",
    "gmm = GaussianMixture(n_components=optimal_k, random_state=42)\n",
    "df['Cluster'] = gmm.fit_predict(X_scaled)\n",
    "\n",
    "# Step 1: Box Plot for Age vs Cluster\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([df[df['Cluster'] == i]['Age'] for i in range(optimal_k)], labels=[f'Cluster {i}' for i in range(optimal_k)])\n",
    "plt.title('Box Plot of Age by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Box Plot for Spending Score vs Cluster\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([df[df['Cluster'] == i]['Spending Score (1-100)'] for i in range(optimal_k)], labels=[f'Cluster {i}' for i in range(optimal_k)])\n",
    "plt.title('Box Plot of Spending Score by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Spending Score (1-100)')\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Box Plot for Income vs Cluster\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([df[df['Cluster'] == i]['Annual Income (k$)'] for i in range(optimal_k)], labels=[f'Cluster {i}' for i in range(optimal_k)])\n",
    "plt.title('Box Plot of Income by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Annual Income (k$)')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Calculate and Display Mean Values for Each Cluster\n",
    "cluster_means = df.groupby('Cluster')[['Age', 'Spending Score (1-100)', 'Annual Income (k$)']].mean()\n",
    "print(\"\\nMean Values for Each Cluster:\")\n",
    "print(cluster_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dddb64-adf7-4244-8f10-ab8ffc14d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Mall_customers.csv')\n",
    "\n",
    "# Select features for clustering (Age, Spending Score, and Annual Income)\n",
    "X = df[['Age', 'Spending Score (1-100)', 'Annual Income (k$)']]\n",
    "\n",
    "# Standardize the data \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply HAC with 3 clusters \n",
    "hac = AgglomerativeClustering(n_clusters=3)\n",
    "df['Cluster'] = hac.fit_predict(X_scaled)\n",
    "\n",
    "# Step 1: Box Plot for Age vs Cluster\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([df[df['Cluster'] == i]['Age'] for i in range(3)], labels=[f'Cluster {i}' for i in range(3)])\n",
    "plt.title('Box Plot of Age by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Box Plot for Spending Score vs Cluster\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([df[df['Cluster'] == i]['Spending Score (1-100)'] for i in range(3)], labels=[f'Cluster {i}' for i in range(3)])\n",
    "plt.title('Box Plot of Spending Score by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Spending Score (1-100)')\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Box Plot for Income vs Cluster\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([df[df['Cluster'] == i]['Annual Income (k$)'] for i in range(3)], labels=[f'Cluster {i}' for i in range(3)])\n",
    "plt.title('Box Plot of Income by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Annual Income (k$)')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Dendrogram for HAC\n",
    "plt.figure(figsize=(12, 8))\n",
    "Z = sch.linkage(X_scaled, method='ward')  # Create linkage matrix using Ward's method\n",
    "sch.dendrogram(Z, no_labels=True)  # Remove labels on the x-axis to avoid clutter\n",
    "plt.title('Dendrogram for HAC')\n",
    "plt.xlabel('Customer Index')  # Simplified x-axis label\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Calculate and Display Mean Values for Each Cluster\n",
    "cluster_means = df.groupby('Cluster')[['Age', 'Spending Score (1-100)', 'Annual Income (k$)']].mean()\n",
    "print(\"\\nMean Values for Each Cluster:\")\n",
    "print(cluster_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e27e1-82d4-4a6f-bac6-a8abefb4d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Housing.csv')\n",
    "\n",
    "# Calculate the overall median of 'median_house_value'\n",
    "overall_median = df['median_house_value'].median()\n",
    "\n",
    "# Create a Housing Median Price Index\n",
    "df['housing_median_price_index'] = df['median_house_value'] / overall_median\n",
    "\n",
    "# Plot the histogram for the Housing Median Price Index\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['housing_median_price_index'], bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Housing Median Price Index')\n",
    "plt.xlabel('Housing Median Price Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1e0cb-b39f-4570-9b2a-c50e5e071f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('Housing.csv')\n",
    "\n",
    "# Step 2: One-Hot Encoding for the categorical column 'ocean_proximity'\n",
    "df = pd.get_dummies(df, columns=['ocean_proximity'], drop_first=True)\n",
    "\n",
    "# Step 3: Drop rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Step 4: Define features and target\n",
    "X = df_clean.drop(columns=['median_house_value'])  # Features\n",
    "y = df_clean['median_house_value']  # Target\n",
    "\n",
    "# Step 5: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model 1: Linear Regression vs Polynomial Linear Regression\n",
    "# Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "\n",
    "# Polynomial Linear Regression\n",
    "poly = PolynomialFeatures(degree=2)  # You can adjust the degree\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_poly, y_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "y_pred_poly = poly_reg.predict(X_test_poly)\n",
    "\n",
    "# Calculate performance metrics for Linear and Polynomial Regression\n",
    "r2_lin = r2_score(y_test, y_pred_lin)\n",
    "r2_poly = r2_score(y_test, y_pred_poly)\n",
    "rmse_lin = np.sqrt(mean_squared_error(y_test, y_pred_lin))  # RMSE instead of MSE\n",
    "rmse_poly = np.sqrt(mean_squared_error(y_test, y_pred_poly))  # RMSE instead of MSE\n",
    "\n",
    "# Model 2: Lasso Regression \n",
    "lasso = Lasso(alpha=0.1)  # You can adjust the alpha value\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))  # RMSE instead of MSE\n",
    "\n",
    "# Model 3: Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))  # RMSE instead of MSE\n",
    "\n",
    "# Performance Comparison\n",
    "print(\"Linear Regression:\")\n",
    "print(f\"R²: {r2_lin:.4f}, RMSE: {rmse_lin:.4f}\")\n",
    "\n",
    "print(\"\\nPolynomial Linear Regression:\")\n",
    "print(f\"R²: {r2_poly:.4f}, RMSE: {rmse_poly:.4f}\")\n",
    "\n",
    "print(\"\\nLasso Regression:\")\n",
    "print(f\"R²: {r2_lasso:.4f}, RMSE: {rmse_lasso:.4f}\")\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(f\"R²: {r2_rf:.4f}, RMSE: {rmse_rf:.4f}\")\n",
    "\n",
    "# Scatter Plot for all Models\n",
    "# Create a figure\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Scatter plot for Linear Regression\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(y_test, y_pred_lin, color='lightblue', edgecolor='black', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Line of perfect prediction\n",
    "plt.title(\"Linear Regression: Actual vs Predicted\")\n",
    "plt.xlabel(\"Actual Median House Value\")\n",
    "plt.ylabel(\"Predicted Median House Value\")\n",
    "\n",
    "# Scatter plot for Polynomial Linear Regression\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(y_test, y_pred_poly, color='lightblue', edgecolor='black', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Line of perfect prediction\n",
    "plt.title(\"Polynomial Linear Regression: Actual vs Predicted\")\n",
    "plt.xlabel(\"Actual Median House Value\")\n",
    "plt.ylabel(\"Predicted Median House Value\")\n",
    "\n",
    "# Scatter plot for Lasso Regression\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(y_test, y_pred_lasso, color='lightblue', edgecolor='black', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Line of perfect prediction\n",
    "plt.title(\"Lasso Regression: Actual vs Predicted\")\n",
    "plt.xlabel(\"Actual Median House Value\")\n",
    "plt.ylabel(\"Predicted Median House Value\")\n",
    "\n",
    "# Scatter plot for Random Forest\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(y_test, y_pred_rf, color='lightblue', edgecolor='black', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Line of perfect prediction\n",
    "plt.title(\"Random Forest: Actual vs Predicted\")\n",
    "plt.xlabel(\"Actual Median House Value\")\n",
    "plt.ylabel(\"Predicted Median House Value\")\n",
    "\n",
    "# layout and show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance for Random Forest\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Visualize feature importance (Random Forest)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(X.columns, feature_importances, color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473bbcff-14bb-49e0-bfd1-4b9ff7ee62c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the liver disease dataset\n",
    "df = pd.read_csv('Liver.csv', encoding='ISO-8859-1')  # Change the file path accordingly\n",
    "\n",
    "# Encode categorical columns\n",
    "df['Gender of the patient'] = df['Gender of the patient'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# 1. Correlation Matrix\n",
    "# Calculate the correlation matrix for numerical columns\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Plot the correlation matrix using seaborn heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a22ab-62da-48fb-bd8c-adf8f21c2847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Count Plot\n",
    "# Plot the count plot for the target variable 'Result' to check the balance\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Result', data=df)  # Removed palette to prevent the warning\n",
    "plt.title('Distribution of Target Variable (Liver Disease)')\n",
    "plt.xlabel('Result (0 = No, 1 = Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6220d01c-6f61-44dd-a965-e6aec00c8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, roc_curve, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Liver.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Remove rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Result', axis=1)  # 'Result' is the target column\n",
    "y = df['Result']\n",
    "\n",
    "# Convert target variable (class 2 → 1 and class 1 → 0 for binary classification)\n",
    "y = y - 1  \n",
    "\n",
    "# Encode categorical features\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    X[col] = encoder.fit_transform(X[col])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize models with class balancing where applicable\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced'),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVC': SVC(probability=True, class_weight='balanced'),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "for model_name, model in models.items():\n",
    "    # Train all models on SMOTE-balanced data\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]  # Probability for class 1\n",
    "    \n",
    "    # Calculate metrics (Using roc_auc_score directly)\n",
    "    auc_value = roc_auc_score(y_test, y_prob)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Print Model Performance Metrics\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"ROC AUC Score: {auc_value:.4f}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, color='b', label=f'ROC AUC = {auc_value:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for {model_name}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 1', 'Class 2'])\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Feature Importance (Only for Random Forest)\n",
    "    if model_name == 'Random Forest':\n",
    "        feature_importances = model.feature_importances_\n",
    "        features = X.columns\n",
    "        importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "        importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "        plt.title('Feature Importance (Random Forest)')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
